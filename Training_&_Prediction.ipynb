{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12506921,"sourceType":"datasetVersion","datasetId":7893823},{"sourceId":12525959,"sourceType":"datasetVersion","datasetId":7906980},{"sourceId":12537369,"sourceType":"datasetVersion","datasetId":7914998},{"sourceId":12736310,"sourceType":"datasetVersion","datasetId":8050678}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install nlpaug\n!pip install nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:41:45.012852Z","iopub.execute_input":"2025-08-12T16:41:45.013125Z","iopub.status.idle":"2025-08-12T16:41:51.297790Z","shell.execute_reply.started":"2025-08-12T16:41:45.013091Z","shell.execute_reply":"2025-08-12T16:41:51.297113Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nlpaug in /usr/local/lib/python3.11/dist-packages (1.1.11)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.2.3)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (2.32.4)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.13.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (3.18.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug) (2025.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug) (2025.6.15)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.7)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (4.14.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.2->nlpaug) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.2->nlpaug) (2024.2.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nfinal_df = pd.read_csv('/kaggle/input/last-input-for-ml-dl/final_train_with_stopwords.csv') \ndev = pd.read_csv('/kaggle/input/last-input-for-ml-dl/final_dev_with_stopwords (1).csv')\n# test = pd.read_csv('/kaggle/input/final-dataset-with-stop-words/final_test_with_stopwords.csv',delimiter=',')\ntest_label = pd.read_csv('/kaggle/input/last-input-for-ml-dl/final_test_with_stopwords.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.276542Z","iopub.execute_input":"2025-08-12T16:42:30.277292Z","iopub.status.idle":"2025-08-12T16:42:30.652276Z","shell.execute_reply.started":"2025-08-12T16:42:30.277261Z","shell.execute_reply":"2025-08-12T16:42:30.651706Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"final_df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.653452Z","iopub.execute_input":"2025-08-12T16:42:30.653710Z","iopub.status.idle":"2025-08-12T16:42:30.674591Z","shell.execute_reply.started":"2025-08-12T16:42:30.653685Z","shell.execute_reply":"2025-08-12T16:42:30.673773Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"132"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"final_df['text'].duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.675417Z","iopub.execute_input":"2025-08-12T16:42:30.675674Z","iopub.status.idle":"2025-08-12T16:42:30.682009Z","shell.execute_reply.started":"2025-08-12T16:42:30.675655Z","shell.execute_reply":"2025-08-12T16:42:30.681408Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"206"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"final_df.drop_duplicates(subset='text',inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.683342Z","iopub.execute_input":"2025-08-12T16:42:30.683579Z","iopub.status.idle":"2025-08-12T16:42:30.696899Z","shell.execute_reply.started":"2025-08-12T16:42:30.683563Z","shell.execute_reply":"2025-08-12T16:42:30.696329Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"final_df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.697644Z","iopub.execute_input":"2025-08-12T16:42:30.697870Z","iopub.status.idle":"2025-08-12T16:42:30.714248Z","shell.execute_reply.started":"2025-08-12T16:42:30.697854Z","shell.execute_reply":"2025-08-12T16:42:30.713546Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"dev.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.714949Z","iopub.execute_input":"2025-08-12T16:42:30.715224Z","iopub.status.idle":"2025-08-12T16:42:30.725598Z","shell.execute_reply.started":"2025-08-12T16:42:30.715196Z","shell.execute_reply":"2025-08-12T16:42:30.724836Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"dev['text'].duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.726301Z","iopub.execute_input":"2025-08-12T16:42:30.726507Z","iopub.status.idle":"2025-08-12T16:42:30.734592Z","shell.execute_reply.started":"2025-08-12T16:42:30.726491Z","shell.execute_reply":"2025-08-12T16:42:30.733970Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dev.drop_duplicates(subset='text',inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.735326Z","iopub.execute_input":"2025-08-12T16:42:30.735608Z","iopub.status.idle":"2025-08-12T16:42:30.746526Z","shell.execute_reply.started":"2025-08-12T16:42:30.735593Z","shell.execute_reply":"2025-08-12T16:42:30.746016Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"test_label['text'].duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.747198Z","iopub.execute_input":"2025-08-12T16:42:30.747432Z","iopub.status.idle":"2025-08-12T16:42:30.759036Z","shell.execute_reply.started":"2025-08-12T16:42:30.747410Z","shell.execute_reply":"2025-08-12T16:42:30.758384Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"15"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"final_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.761722Z","iopub.execute_input":"2025-08-12T16:42:30.761964Z","iopub.status.idle":"2025-08-12T16:42:30.772898Z","shell.execute_reply.started":"2025-08-12T16:42:30.761947Z","shell.execute_reply":"2025-08-12T16:42:30.772307Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"label\nnot_applicable    3600\nhope              1820\nhate              1264\nName: count, dtype: int64"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"dev['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.773596Z","iopub.execute_input":"2025-08-12T16:42:30.773850Z","iopub.status.idle":"2025-08-12T16:42:30.784257Z","shell.execute_reply.started":"2025-08-12T16:42:30.773835Z","shell.execute_reply":"2025-08-12T16:42:30.783616Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"label\nnot_applicable    799\nhope              404\nhate              261\nName: count, dtype: int64"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dev['text'].isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.785050Z","iopub.execute_input":"2025-08-12T16:42:30.785493Z","iopub.status.idle":"2025-08-12T16:42:30.795429Z","shell.execute_reply.started":"2025-08-12T16:42:30.785468Z","shell.execute_reply":"2025-08-12T16:42:30.794817Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"dev.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.796170Z","iopub.execute_input":"2025-08-12T16:42:30.796374Z","iopub.status.idle":"2025-08-12T16:42:30.809049Z","shell.execute_reply.started":"2025-08-12T16:42:30.796352Z","shell.execute_reply":"2025-08-12T16:42:30.808445Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"dev.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.809798Z","iopub.execute_input":"2025-08-12T16:42:30.810050Z","iopub.status.idle":"2025-08-12T16:42:30.830360Z","shell.execute_reply.started":"2025-08-12T16:42:30.810029Z","shell.execute_reply":"2025-08-12T16:42:30.829801Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                                text           label\n0  اخترتك حبا لقلبي فلا تكن بغيابك له وجعا كنت وم...            hope\n1  ضعي ما تشاءين من مساحيق التجميل فانا اتلذذ في ...  not_applicable\n2  ان شعوري بالغضب والرغبه في المضي قدما في اشياء...            hope\n3  بل ايران جندت نفسها للشيطان ومشروعها الطاءفي و...  not_applicable\n4  الحب ياتي مره واحده في العمر او قد لا ياتي ابد...            hope","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>اخترتك حبا لقلبي فلا تكن بغيابك له وجعا كنت وم...</td>\n      <td>hope</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ضعي ما تشاءين من مساحيق التجميل فانا اتلذذ في ...</td>\n      <td>not_applicable</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ان شعوري بالغضب والرغبه في المضي قدما في اشياء...</td>\n      <td>hope</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>بل ايران جندت نفسها للشيطان ومشروعها الطاءفي و...</td>\n      <td>not_applicable</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>الحب ياتي مره واحده في العمر او قد لا ياتي ابد...</td>\n      <td>hope</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"x = final_df['text'].apply(lambda x: len(str(x).split(\" \")))\ny = dev['text'].apply(lambda x: len(str(x).split(\" \")))\nz = test_label['text'].apply(lambda x: len(str(x).split(\" \")))\nprint(x.min(),x.max(),y.min(),y.max(),z.min(),z.max())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.830989Z","iopub.execute_input":"2025-08-12T16:42:30.831732Z","iopub.status.idle":"2025-08-12T16:42:30.854788Z","shell.execute_reply.started":"2025-08-12T16:42:30.831704Z","shell.execute_reply":"2025-08-12T16:42:30.854022Z"}},"outputs":[{"name":"stdout","text":"1 130 1 101 1 112\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    accuracy = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average='weighted')\n    return {\n        'accuracy': accuracy,\n        'f1': f1\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T16:42:30.855707Z","iopub.execute_input":"2025-08-12T16:42:30.856417Z","iopub.status.idle":"2025-08-12T16:42:31.410544Z","shell.execute_reply.started":"2025-08-12T16:42:30.856395Z","shell.execute_reply":"2025-08-12T16:42:31.409811Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport pandas as pd\nfrom transformers import TrainingArguments\nfrom transformers import EarlyStoppingCallback\n\n# === Step 1: Encode Labels ===\nle = LabelEncoder()\nfinal_df['label_enc'] = le.fit_transform(final_df['label'])\ndev['label_enc'] = le.fit_transform(dev['label'])\n# Map of encoded labels to original:\nprint(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))\n\n# train_df, val_df = train_test_split(final_df, test_size=0.2, random_state=42, stratify=final_df['label_enc'])\ntrain_df = final_df\nval_df = dev\n\n# === Step 2: Prepare Tokenizer & Model ===\nmodel_name = \"aubmindlab/bert-large-arabertv02\" \n# model_name = \"UBC-NLP/MARBERT\"\n# model_name = \"asafaya/bert-base-arabic\"\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(le.classes_))\n\n# dropout rates\nmodel.config.hidden_dropout_prob = 0.2\nmodel.config.attention_probs_dropout_prob = 0.2\n\n# === Step 3: Dataset Class ===\nclass EmotionDataset(Dataset):\n    def __init__(self, texts, labels=None):\n        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=256)\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels is not None:\n            item['labels'] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings['input_ids'])\n\n# === Step 4: Prepare Datasets ===\ntrain_dataset = EmotionDataset(train_df['text'].tolist(), train_df['label_enc'].tolist())\nval_dataset = EmotionDataset(val_df['text'].tolist(), val_df['label_enc'].tolist())\n# For dev dataset, since no labels, just encode texts only\ndev_dataset = EmotionDataset(test_label['text'].tolist())\n\n# === Step 5: Training Arguments ===\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=20,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    eval_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=20,\n    disable_tqdm=False,\n    save_strategy=\"epoch\",\n    save_total_limit=1,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    # greater_is_better=True,\n    report_to=\"none\",\n    learning_rate=3.5e-6,\n    weight_decay=0.01,  \n    warmup_ratio=0.1, \n    # gradient_accumulation_steps=2,  \n)\n\n\n# === Step 6: Trainer Initialization ===\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,  \n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=4)] \n)\n\n# === Step 7: Train ===\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T17:31:00.185460Z","iopub.execute_input":"2025-08-12T17:31:00.186043Z","iopub.status.idle":"2025-08-12T19:35:58.555367Z","shell.execute_reply.started":"2025-08-12T17:31:00.186020Z","shell.execute_reply":"2025-08-12T19:35:58.554563Z"}},"outputs":[{"name":"stdout","text":"Label mapping: {'hate': 0, 'hope': 1, 'not_applicable': 2}\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-large-arabertv02 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='5852' max='8360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5852/8360 2:04:53 < 53:32, 0.78 it/s, Epoch 14/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.036800</td>\n      <td>1.032201</td>\n      <td>0.505464</td>\n      <td>0.432336</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.003700</td>\n      <td>0.944895</td>\n      <td>0.553279</td>\n      <td>0.452039</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.879200</td>\n      <td>0.837504</td>\n      <td>0.584016</td>\n      <td>0.524553</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.743800</td>\n      <td>0.746317</td>\n      <td>0.647541</td>\n      <td>0.637644</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.762700</td>\n      <td>0.719422</td>\n      <td>0.661202</td>\n      <td>0.655732</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.674100</td>\n      <td>0.710900</td>\n      <td>0.662568</td>\n      <td>0.658225</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.647800</td>\n      <td>0.709959</td>\n      <td>0.670765</td>\n      <td>0.667545</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.682200</td>\n      <td>0.709258</td>\n      <td>0.664617</td>\n      <td>0.662323</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.632900</td>\n      <td>0.705459</td>\n      <td>0.668716</td>\n      <td>0.666076</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.598900</td>\n      <td>0.702428</td>\n      <td>0.675546</td>\n      <td>0.671950</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.727300</td>\n      <td>0.707558</td>\n      <td>0.673497</td>\n      <td>0.672584</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.604100</td>\n      <td>0.720246</td>\n      <td>0.665301</td>\n      <td>0.664738</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.567500</td>\n      <td>0.718252</td>\n      <td>0.667350</td>\n      <td>0.665491</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.582700</td>\n      <td>0.722847</td>\n      <td>0.663934</td>\n      <td>0.663673</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=5852, training_loss=0.7497044154738859, metrics={'train_runtime': 7493.6674, 'train_samples_per_second': 17.839, 'train_steps_per_second': 1.116, 'total_flos': 2.844437412588005e+16, 'train_loss': 0.7497044154738859, 'epoch': 14.0})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(eval_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T19:36:05.044457Z","iopub.execute_input":"2025-08-12T19:36:05.044801Z","iopub.status.idle":"2025-08-12T19:36:39.409259Z","shell.execute_reply.started":"2025-08-12T19:36:05.044740Z","shell.execute_reply":"2025-08-12T19:36:39.408510Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 0.7024281620979309, 'eval_accuracy': 0.6755464480874317, 'eval_f1': 0.6719501002930802, 'eval_runtime': 34.3573, 'eval_samples_per_second': 42.611, 'eval_steps_per_second': 2.678, 'epoch': 14.0}\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# === Step 8: Predict on dev dataset ===\npredictions = trainer.predict(dev_dataset)\npreds = np.argmax(predictions.predictions, axis=-1)\npred_labels = le.inverse_transform(preds)\n\n# === Step 9: Add predictions to dev and save ===\n# test['prediction'] = pred_labels\n# print(test[['id', 'prediction']].head())\n# test = test[['id', 'prediction']]\n\n# test.to_csv('prediction.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T19:36:39.410535Z","iopub.execute_input":"2025-08-12T19:36:39.410804Z","iopub.status.idle":"2025-08-12T19:37:13.000734Z","shell.execute_reply.started":"2025-08-12T19:36:39.410778Z","shell.execute_reply":"2025-08-12T19:37:13.000124Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T17:28:58.161031Z","iopub.execute_input":"2025-08-12T17:28:58.161221Z","iopub.status.idle":"2025-08-12T17:28:58.164668Z","shell.execute_reply.started":"2025-08-12T17:28:58.161207Z","shell.execute_reply":"2025-08-12T17:28:58.163886Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# test['prediction'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T17:28:58.165769Z","iopub.execute_input":"2025-08-12T17:28:58.166049Z","iopub.status.idle":"2025-08-12T17:28:58.176184Z","shell.execute_reply.started":"2025-08-12T17:28:58.166032Z","shell.execute_reply":"2025-08-12T17:28:58.175539Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# import zipfile\n# with zipfile.ZipFile(\"prediction.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n#     zipf.write(\"prediction.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T17:28:58.176979Z","iopub.execute_input":"2025-08-12T17:28:58.177224Z","iopub.status.idle":"2025-08-12T17:28:58.186507Z","shell.execute_reply.started":"2025-08-12T17:28:58.177200Z","shell.execute_reply":"2025-08-12T17:28:58.185934Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from sklearn.metrics import classification_report, precision_recall_fscore_support\n\ny_true = test_label['label']\ny_pred = pred_labels\n\n# Labels in a fixed order\nlabels = [\"hate\", \"hope\", \"not_applicable\"]\n\n# 1. Full report (per class + macro avg)\nprint(classification_report(y_true, y_pred, labels=labels, digits=3))\n\n# 2. Macro precision, recall, f1 only\nprecision, recall, f1, _ = precision_recall_fscore_support(\n    y_true, y_pred, labels=labels, average=\"macro\"\n)\nprint(f\"Macro Precision: {precision:.3f}\")\nprint(f\"Macro Recall:    {recall:.3f}\")\nprint(f\"Macro F1-score:  {f1:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T19:37:13.001676Z","iopub.execute_input":"2025-08-12T19:37:13.001985Z","iopub.status.idle":"2025-08-12T19:37:13.061519Z","shell.execute_reply.started":"2025-08-12T19:37:13.001964Z","shell.execute_reply":"2025-08-12T19:37:13.060805Z"}},"outputs":[{"name":"stdout","text":"                precision    recall  f1-score   support\n\n          hate      0.684     0.672     0.678       287\n          hope      0.697     0.616     0.654       422\nnot_applicable      0.697     0.746     0.721       768\n\n      accuracy                          0.695      1477\n     macro avg      0.693     0.678     0.684      1477\n  weighted avg      0.695     0.695     0.693      1477\n\nMacro Precision: 0.693\nMacro Recall:    0.678\nMacro F1-score:  0.684\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}